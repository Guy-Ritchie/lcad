GOOGLE_API_KEY=""
GROQ_API_KEY=""

## PROVIDER - GOOGLE
# Gemini Models
# REFERENCE: https://ai.google.dev/gemini-api/docs/models/gemini
# Experimental Models
# REFERENCE: https://ai.google.dev/gemini-api/docs/models/experimental-models

# Fall back models / model tier configs
PREMIUM_MODEL="gemini-1.0-pro"
# 2 RPM / 32k Tokens Per Min / 50 Req's Per Day
EMBEDDING_MODEL="text-embedding-004"
# 1500 Req's Per Min / 2048 tokens - Input Token Limit / 768 - Output Dimension size
DEFAULT_MODEL="gemini-1.5-flash"
# 15 RPM / 1M Tokens Per Min / 1500 Req's Per Day
DEFAULT_FALLBACK_MODEL="gemini-1.5-flash"
# 15 RPM / 1M Tokens Per Min / 1500 Req's Per Day
ANOTHER_FALLBACK_MODEL="gemini-1.5-flash-8b"
EXPERIMENTAL_MODEL="gemini-2.0-flash-exp"
# 10 RPM / 4M Tokens Per Min / 1500 Req's Per Day

## PROVIDER - GROQ
# Groq Models
# REFERENCE: https://console.groq.com/docs/models
# Fall back models / model tier configs
# PREMIUM_GROQ_MODEL="llama-3.3-70b-specdec"
PREMIUM_GROQ_MODEL="llama-3.3-70b-versatile"
# 30 RPM / 1k Req's Per Day / 6k Tokens Per Min / 100k Tokens Per Day
DEFAULT_GROQ_MODEL="llama-3.1-8b-instant"
# 30 RPM / 14.4k Req's Per Day / 20k Tokens Per Min / 500k Tokens Per Day
DEFAULT_FALLBACK_GROQ_MODEL="llama3-groq-70b-8192-tool-use-preview"
# 30 RPM / 14.4k Req's Per Day / 15k Tokens Per Min / 500k Tokens Per Day
ANOTHER_FALLBACK_GROQ_MODEL="llama3-groq-8b-8192-tool-use-preview"
# 30 RPM / 14.4k Req's Per Day / 15k Tokens Per Min / 500k Tokens Per Day
MIXTRAL_GROQ_MODEL="mixtral-8x7b-32768"
# 30 RPM / 14.4k Req's Per Day / 5k Tokens Per Min / 500k Tokens Per Day

